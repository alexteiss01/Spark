{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modèles de Recommandations."
      ],
      "metadata": {
        "id": "BZkxs_2fsSFV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWwwQte9sBpc"
      },
      "source": [
        "## 1. Librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1i_1-BG0sGLP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2Mp9mw2pvRYh"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark import StorageLevel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uWnZpNXQHbE",
        "outputId": "0269fcf4-08d9-4eb6-f4f0-b3551bee9979"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "V5A8NPJ-QUQf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP7yfpU9vvlj"
      },
      "source": [
        "## 2. Création d'une session Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vPbydNWEvn94"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MyALS\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Ge7lnJxbji"
      },
      "source": [
        "## 3. Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8BF08fWv4p1",
        "outputId": "6e13368a-97b8-479c-cbf2-4689d91d5900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E-d1oGWRxtw-"
      },
      "outputs": [],
      "source": [
        "df = spark.read.parquet(\"/content/drive/MyDrive/ml-32m/df.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06MTtHiZ5DR1",
        "outputId": "ea1e0931-5591-465f-e294-e99d02c4bf97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+------+------+----------+--------------------+----+--------------------+\n",
            "|movieId|               title|              genres|userId|rating| timestamp|         genres_list|year|    title_sans_annee|\n",
            "+-------+--------------------+--------------------+------+------+----------+--------------------+----+--------------------+\n",
            "|   8970|Finding Neverland...|               Drama| 62769|   5.0|1426961515|             [Drama]|2004|   Finding Neverland|\n",
            "|  27815|Chorus, The (Chor...|               Drama| 62769|   3.5|1426959562|             [Drama]|2004|Chorus, The (Chor...|\n",
            "|  30707|Million Dollar Ba...|               Drama| 62769|   4.0|1426959541|             [Drama]|2004| Million Dollar Baby|\n",
            "|  33166|        Crash (2004)|         Crime|Drama| 62769|   5.0|1426961486|      [Crime, Drama]|2004|               Crash|\n",
            "|  40819|Walk the Line (2005)|Drama|Musical|Rom...| 62769|   3.0|1426961490|[Drama, Musical, ...|2005|       Walk the Line|\n",
            "+-------+--------------------+--------------------+------+------+----------+--------------------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rrD6j_SVdQl"
      },
      "source": [
        "## 4. Modélisation avec Spark MLlib : ALS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Préparation des données"
      ],
      "metadata": {
        "id": "ia_mD4ZpnTCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w4-DaAQ2U9C8"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import rand\n",
        "\n",
        "# Sous-échantillonage\n",
        "\n",
        "df_sample = df.sample(withReplacement=False, fraction=0.5, seed=333)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split par proportion stratifiée:\n",
        "pour chaque utilisateur, on fait un split aléatoire ou temporel de type 80/20.\n",
        "On s’assure que pour chaque utilisateur, il reste suffisamment d’interactions dans les deux ensembles.\n",
        "\n",
        "Pourquoi? Parce qu'un split classique ne garantit pas la présence dans le test, d'interactions user-film utilisée pendant l'entraînement.\n"
      ],
      "metadata": {
        "id": "fTtS0qtV-sN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Proportion du train\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Création d'un rang temporel par utilisateur\n",
        "window = Window.partitionBy(\"userId\").orderBy(F.col(\"timestamp\"))\n",
        "df_strat = df_sample.withColumn(\"rank\", F.row_number().over(window))\n",
        "\n",
        "# Nombre d'interactions par utilisateur\n",
        "user_counts = df_strat.groupBy(\"userId\").agg(F.max(\"rank\").alias(\"count_per_user_join\"))\n",
        "\n",
        "# Jointure avec df_strat pour chaque ligne\n",
        "df_strat = df_strat.join(user_counts, on=\"userId\", how=\"left\")\n",
        "\n",
        "# Seuil train/test par utilisateur\n",
        "df_strat = df_strat.withColumn(\n",
        "    \"train_cutoff\",\n",
        "    (F.col(\"count_per_user_join\") * train_ratio).cast(\"int\")\n",
        ")\n",
        "\n",
        "# Split stratifié : les ranks <= cutoff vont au train, le reste au test\n",
        "train = df_strat.filter(F.col(\"rank\") <= F.col(\"train_cutoff\"))\n",
        "test  = df_strat.filter(F.col(\"rank\") >  F.col(\"train_cutoff\"))"
      ],
      "metadata": {
        "id": "jmJEW6mNs8tX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemins de sauvegarde dans ton Google Drive\n",
        "train_path = \"/content/drive/MyDrive/ml-32m/train_data\"\n",
        "test_path = \"/content/drive/MyDrive/ml-32m/test_data\"\n",
        "\n",
        "# Sauvegarde au format Parquet (format efficace et recommandé pour Spark)\n",
        "train.write.mode(\"overwrite\").parquet(train_path)\n",
        "test.write.mode(\"overwrite\").parquet(test_path)"
      ],
      "metadata": {
        "id": "Ffz8vnCKVtmx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "liste des utilisateurs dans le test"
      ],
      "metadata": {
        "id": "pvzgZ7lp-3W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_test = test.select(\"userId\").distinct()"
      ],
      "metadata": {
        "id": "aRBx_ybp4Tya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "liste des utilisateurs dans le train"
      ],
      "metadata": {
        "id": "PrsD_5-t-9p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_train = train.select(\"userId\").distinct()"
      ],
      "metadata": {
        "id": "0y1ifcon4VcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recherche d'utilisateurs du test absents du train"
      ],
      "metadata": {
        "id": "hCkv7MlB_C2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_missing = users_test.join(users_train, on=\"userId\", how=\"left_anti\")\n",
        "users_missing.show()  # affichge des userId à problème"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOSnpgox4XMK",
        "outputId": "5177cfe6-96c6-4d67-ab26-6cccddc44b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|userId|\n",
            "+------+\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHGzbwTAcVuV"
      },
      "source": [
        "### 4.2. Entraînement de l'ALS (70% des données)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UuBkPCxcUzP"
      },
      "outputs": [],
      "source": [
        "# Extraction des colonnes nécessaires\n",
        "\n",
        "als_train = train.select(\"userId\", \"movieId\", \"rating\")\n",
        "als_test  = test.select(\"userId\", \"movieId\", \"rating\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnDbtJGde_1V"
      },
      "outputs": [],
      "source": [
        "# ALS (grid search sur les hyper paramètres)\n",
        "\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Initialisation du modèle ALS\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True\n",
        ")\n",
        "\n",
        "# Recherche sur rank, regParam, maxIter\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(als.rank, [5, 10, 20]) \\\n",
        "    .addGrid(als.regParam, [0.01, 0.05, 0.1]) \\\n",
        "    .addGrid(als.maxIter, [5, 10]) \\\n",
        "    .build()\n",
        "\n",
        "# RMSE comme critère de sélection\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "cv = CrossValidator(\n",
        "    estimator=als,\n",
        "    estimatorParamMaps=param_grid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=2\n",
        ")\n",
        "\n",
        "# Entraînement pour obtenir les meilleurs hyperparamètres\n",
        "cv_model = cv.fit(als_train)\n",
        "\n",
        "# Meilleur modèle\n",
        "best_als_model = cv_model.bestModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde du meilleur modèle dans un fichier\n",
        "\n",
        "best_als_model.write().overwrite().save(\"/content/drive/MyDrive/ml-32m/best_als_model\")"
      ],
      "metadata": {
        "id": "TB_VxXjdCaL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du meilleur modèle\n",
        "\n",
        "from pyspark.ml.recommendation import ALSModel\n",
        "\n",
        "best_als_model = ALSModel.load(\"/content/drive/MyDrive/ml-32m/best_als_model\")\n"
      ],
      "metadata": {
        "id": "YUJ7lkL1Sn8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT-8r2JKDDZ9",
        "outputId": "2c5b0c20-a8ee-4f13-c327-5bcc851baf27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best rank: 20\n",
            "Best regParam: 0.1\n",
            "Best maxIter: 10\n"
          ]
        }
      ],
      "source": [
        "# Récupérer la valeur de chaque hyperparamètre\n",
        "best_rank     = best_als_model._java_obj.parent().getRank()\n",
        "best_regparam = best_als_model._java_obj.parent().getRegParam()\n",
        "best_maxiter  = best_als_model._java_obj.parent().getMaxIter()\n",
        "\n",
        "print(f\"Best rank: {best_rank}\")\n",
        "print(f\"Best regParam: {best_regparam}\")\n",
        "print(f\"Best maxIter: {best_maxiter}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Prédictions sur le test"
      ],
      "metadata": {
        "id": "v7POURqRpjJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKPXq59TDL0L",
        "outputId": "b05152e1-1c13-4de5-cb3e-902c8c3c4810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE du meilleur modèle sur le test: 0.8331\n"
          ]
        }
      ],
      "source": [
        "# Prédiction sur le test set\n",
        "pred = best_als_model.transform(test)\n",
        "\n",
        "# Calcul du RMSE\n",
        "rmse_best = evaluator.evaluate(pred)\n",
        "print(f\"RMSE du meilleur modèle sur le test: {rmse_best:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsOXmvuGDOKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a42e23-b7da-4c73-d239-3c4b10aebb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE moyens sur la grille (validation croisée): [np.float64(0.8728500501005159), np.float64(0.8495061871870658), np.float64(0.8586408014429849), np.float64(0.8365147767124903), np.float64(0.8468710866059251), np.float64(0.8328230406778426), np.float64(0.8748739987335976), np.float64(0.8664983749685551), np.float64(0.8603939721664892), np.float64(0.8340971326443893), np.float64(0.8485555402573826), np.float64(0.8262200448722843), np.float64(0.8925770618732198), np.float64(0.8991618234813956), np.float64(0.8615430240322999), np.float64(0.8345654896407388), np.float64(0.8536234982073747), np.float64(0.824447213078618)]\n"
          ]
        }
      ],
      "source": [
        "# RMSE moyens de chaque configuration de la grille (sur les folds CV)\n",
        "\n",
        "print(\"RMSE moyens sur la grille (validation croisée):\", cv_model.avgMetrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4. Recommandations"
      ],
      "metadata": {
        "id": "WdIn9pMSN8W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 des utilisateurs susceptibles d'apprécier chaque film\n",
        "recommandations_items = best_als_model.recommendForAllItems(5)\n",
        "recommandations_items.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KQKLW4WN7Xs",
        "outputId": "073c89b6-8c35-4079-cd36-bcec7b6e5826",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------------------------------------------------------------------+\n",
            "|movieId|recommendations                                                                                       |\n",
            "+-------+------------------------------------------------------------------------------------------------------+\n",
            "|1      |[{22571, 5.710531}, {48515, 5.449351}, {36189, 5.4239635}, {197988, 5.418619}, {17782, 5.410211}]     |\n",
            "|3      |[{60356, 4.94844}, {14, 4.9207144}, {155152, 4.8754106}, {126492, 4.830433}, {128408, 4.8092833}]     |\n",
            "|5      |[{126492, 4.8918767}, {49191, 4.853008}, {144110, 4.845821}, {135288, 4.8327594}, {99897, 4.782475}]  |\n",
            "|6      |[{66795, 5.316153}, {139881, 5.2190113}, {184156, 5.1247377}, {160024, 5.0900216}, {107562, 5.087736}]|\n",
            "|7      |[{91084, 4.9351034}, {36189, 4.907238}, {149035, 4.8563}, {144110, 4.8562903}, {135288, 4.85153}]     |\n",
            "|9      |[{128408, 4.9791055}, {131535, 4.6913066}, {155152, 4.65787}, {188652, 4.6452737}, {21865, 4.6377215}]|\n",
            "|10     |[{128408, 5.027839}, {66795, 5.016263}, {38558, 4.987841}, {17782, 4.962448}, {189860, 4.912055}]     |\n",
            "|11     |[{36189, 5.226157}, {140699, 5.1440287}, {34931, 5.1243505}, {144110, 5.099813}, {106096, 5.0928607}] |\n",
            "|12     |[{128408, 5.36475}, {181974, 4.987978}, {185027, 4.898973}, {101855, 4.875716}, {4094, 4.8240495}]    |\n",
            "|13     |[{128408, 4.993298}, {97359, 4.904094}, {137012, 4.852277}, {36189, 4.8399315}, {101963, 4.829484}]   |\n",
            "|14     |[{79924, 4.876996}, {139881, 4.750601}, {180553, 4.7479577}, {157639, 4.7446985}, {160383, 4.7412424}]|\n",
            "|16     |[{66795, 5.252383}, {160024, 5.216502}, {107562, 5.215628}, {13000, 5.1405296}, {139881, 5.1364512}]  |\n",
            "|17     |[{18368, 5.5673194}, {63588, 5.487588}, {53861, 5.421864}, {96644, 5.4117203}, {22571, 5.4044027}]    |\n",
            "|18     |[{114721, 5.070141}, {60661, 5.0499024}, {130914, 5.0485997}, {19444, 5.0310397}, {96896, 4.999199}]  |\n",
            "|23     |[{128408, 5.198367}, {101095, 4.9932575}, {185027, 4.976492}, {60356, 4.9104524}, {155152, 4.885373}] |\n",
            "|26     |[{139881, 4.8993115}, {36189, 4.8740683}, {79924, 4.8335743}, {130161, 4.7964363}, {91158, 4.76883}]  |\n",
            "|27     |[{155152, 5.0587187}, {135288, 5.014058}, {137012, 5.009093}, {91449, 4.998273}, {99897, 4.9866843}]  |\n",
            "|31     |[{155152, 5.035746}, {36189, 4.9552393}, {21865, 4.921239}, {137012, 4.9131227}, {79272, 4.8927}]     |\n",
            "|33     |[{128408, 6.295933}, {30923, 5.7092457}, {60356, 5.706737}, {99897, 5.5714574}, {126492, 5.555724}]   |\n",
            "|34     |[{180553, 5.370609}, {22571, 5.3563275}, {197988, 5.3312736}, {48515, 5.172877}, {121692, 5.1585135}] |\n",
            "+-------+------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 des recommandations par utilisateur\n",
        "recommandations = best_als_model.recommendForAllUsers(5)\n",
        "recommandations.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMRlPZJXODCn",
        "outputId": "f2619b33-7341-4331-dc38-99b710397943",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                          |\n",
            "+------+---------------------------------------------------------------------------------------------------------+\n",
            "|5     |[{193389, 4.763201}, {154280, 4.7091417}, {216753, 4.7051306}, {140353, 4.649042}, {222368, 4.5872188}]  |\n",
            "|6     |[{154280, 7.5390973}, {222368, 7.5318093}, {205277, 7.5318093}, {265656, 7.3779125}, {208459, 7.0270233}]|\n",
            "|9     |[{196167, 5.9601665}, {86288, 5.763021}, {190707, 5.7019267}, {265364, 5.6343427}, {138224, 5.5507965}]  |\n",
            "|10    |[{151989, 4.5009556}, {86288, 4.4064307}, {196167, 4.3716984}, {265364, 4.3121934}, {192261, 4.2617397}] |\n",
            "|12    |[{282453, 4.2550135}, {210621, 4.2102065}, {192949, 4.1146603}, {159896, 4.1146603}, {115987, 4.1146603}]|\n",
            "|13    |[{86288, 5.4072747}, {274047, 5.3746395}, {196167, 5.1407795}, {182527, 4.996062}, {222368, 4.880089}]   |\n",
            "|14    |[{216663, 7.8429565}, {217747, 7.74521}, {159761, 7.686201}, {185291, 7.5535026}, {222605, 7.460989}]    |\n",
            "|16    |[{154921, 4.6091824}, {214720, 4.5143614}, {222368, 4.482497}, {205277, 4.482497}, {151989, 4.475053}]   |\n",
            "|17    |[{196167, 6.6689935}, {86288, 6.3089733}, {151989, 6.2986956}, {265364, 6.151856}, {222368, 6.0162387}]  |\n",
            "|18    |[{196167, 6.0295286}, {216663, 5.92387}, {122015, 5.7178793}, {265364, 5.6600204}, {190707, 5.6047487}]  |\n",
            "|23    |[{86288, 6.6976547}, {274047, 6.420019}, {196167, 6.389819}, {265364, 6.1154885}, {151989, 6.035988}]    |\n",
            "|31    |[{265364, 5.6410575}, {192261, 5.4396515}, {216663, 5.4206867}, {143422, 5.3617315}, {167688, 5.3524704}]|\n",
            "|38    |[{151989, 6.274976}, {86288, 5.7255335}, {214720, 5.6868215}, {196167, 5.481001}, {265364, 5.432361}]    |\n",
            "|39    |[{196167, 5.973131}, {189473, 5.970097}, {216663, 5.7604656}, {192497, 5.676113}, {86237, 5.6124425}]    |\n",
            "|46    |[{151989, 5.968766}, {196167, 5.8445573}, {86288, 5.7974544}, {265364, 5.6219516}, {216663, 5.4070907}]  |\n",
            "|48    |[{86288, 5.993033}, {196167, 5.9654493}, {190707, 5.8305764}, {265364, 5.720061}, {159761, 5.674476}]    |\n",
            "|49    |[{86288, 5.713813}, {196167, 5.6147127}, {274047, 5.596096}, {159761, 5.434519}, {154280, 5.3765454}]    |\n",
            "|51    |[{151989, 4.989463}, {196167, 4.421867}, {222368, 4.287655}, {205277, 4.287655}, {283017, 4.2770133}]    |\n",
            "|57    |[{216663, 4.8691354}, {196167, 4.80097}, {164937, 4.7478704}, {122015, 4.7242637}, {155641, 4.684866}]   |\n",
            "|58    |[{151989, 6.4628253}, {214720, 6.1347585}, {86288, 6.076033}, {265364, 5.9134707}, {216663, 5.8743615}]  |\n",
            "+------+---------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5. Evaluations des recommandations"
      ],
      "metadata": {
        "id": "QlJ4xL_gOQTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les recommandations fournies par l'ALS incluent probablement des films déjà vus par l'utilisateur, parce que l'algorithme ALS de Spark ne filtre pas par défaut les anciens items pour chaque utilisateur lors du calcul des recommandations.\n",
        "\n",
        "Pour avoir des métriques d'évaluation qui montre la réelle perfromance de notre modèle, on décide de filtrer les résultats de l'ALS pour ne garder que les films non précédemment vus par chaque utilisateur.\n"
      ],
      "metadata": {
        "id": "gGdnaaUaPrb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Génération de k = 5 recommandations natives de l'ALS\n",
        "\n",
        "k = 5\n",
        "user_recs = best_als_model.recommendForAllUsers(k)"
      ],
      "metadata": {
        "id": "1XXnTv2DOaS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(\"/content/drive/MyDrive/ml-32m/df.parquet\")"
      ],
      "metadata": {
        "id": "gFHUyy8gQ58W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import arrays_zip, explode, col\n",
        "\n",
        "# Accéder aux movieId et rating depuis les recommandations\n",
        "user_recs_exploded = (\n",
        "    user_recs\n",
        "    .select('userId', explode('recommendations').alias('rec'))\n",
        "    .select('userId', col('rec.movieId').alias('movieId'), col('rec.rating').alias('rating'))\n",
        ")\n",
        "already_watched = train.select('userId', 'movieId')\n",
        "final_recs = user_recs_exploded.join(already_watched, ['userId', 'movieId'], 'left_anti')"
      ],
      "metadata": {
        "id": "L7yyewoLAU5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrage des films déjà vus\n",
        "\n",
        "vue = train.withColumn(\"vu\", col(\"rating\"))\n",
        "recs_nouveaux = user_recs_exploded.join(vue.select(\"userId\", \"movieId\"), [\"userId\", \"movieId\"], how=\"left_anti\")"
      ],
      "metadata": {
        "id": "Gs7dNn_uRvoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reconstitution d'un top-k sans doublon"
      ],
      "metadata": {
        "id": "myhQpHmYSCkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remplacement des predictions par les ratings\n",
        "w = Window.partitionBy(\"userId\").orderBy(F.desc(\"rating\"))\n",
        "final_recs = recs_nouveaux.withColumn(\"rank\", F.row_number().over(w)).filter(F.col(\"rank\") <= k)\n",
        "final_recs.show(5)"
      ],
      "metadata": {
        "id": "fn0eTu8OSHoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a9145f-86ec-46fc-c7e5-e969332a61bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+---------+----+\n",
            "|userId|movieId|   rating|rank|\n",
            "+------+-------+---------+----+\n",
            "|     1| 164937| 5.283037|   1|\n",
            "|     1| 193918| 5.109409|   2|\n",
            "|     1| 155641|5.0890317|   3|\n",
            "|     1| 184653|5.0705643|   4|\n",
            "|     1| 168552| 4.846283|   5|\n",
            "+------+-------+---------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On obtiens ainsi le top-k recommandations neuves (hors films déjà vus) pour chaque utilisateur."
      ],
      "metadata": {
        "id": "gGgNsdrLqupJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métriques d'évaluation: top k, recall@k, precision, F1, coverage"
      ],
      "metadata": {
        "id": "v1DiFi_Tq2WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "K = 10  # nombre de recommandations par utilisateur"
      ],
      "metadata": {
        "id": "aO2_avIq3Fww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regroupement des recommandations par utilisateur\n",
        "\n",
        "recs_k = final_recs.groupBy(\"userId\").agg(F.collect_list(\"movieId\").alias(\"rec_movies\"))"
      ],
      "metadata": {
        "id": "bgZu8TRl3QX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de test_positive (ensemble des films appréciés dans le test par utilisateur)\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "seuil_like = 3  # seuil pour 'aimer' un film\n",
        "test_positive = (\n",
        "    test.filter(F.col(\"rating\") >= seuil_like)\n",
        "        .groupBy(\"userId\")\n",
        "        .agg(F.collect_set(\"movieId\").alias(\"test_movies\"))\n",
        ")"
      ],
      "metadata": {
        "id": "l7E_JO6h4ErC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure avec la vérité de test\n",
        "\n",
        "eval_df = recs_k.join(test_positive, \"userId\", \"inner\")"
      ],
      "metadata": {
        "id": "JKilmYj83bX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_f1(rec_movies, test_movies):\n",
        "    rec_set = set(rec_movies or [])\n",
        "    test_set = set(test_movies or [])\n",
        "    nb_hits = len(rec_set & test_set)\n",
        "    precision = nb_hits / len(rec_set) if rec_set else 0\n",
        "    recall = nb_hits / len(test_set) if test_set else 0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "    return float(precision), float(recall), float(f1), nb_hits\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, FloatType, IntegerType\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"precision\", FloatType(), False),\n",
        "    StructField(\"recall\", FloatType(), False),\n",
        "    StructField(\"f1\", FloatType(), False),\n",
        "    StructField(\"nb_hits\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "prf_udf = udf(precision_recall_f1, schema)\n",
        "\n",
        "eval_metrics = eval_df.withColumn(\n",
        "    \"metrics\", prf_udf(\"rec_movies\", \"test_movies\")\n",
        ").select(\n",
        "    \"userId\",\n",
        "    \"metrics.precision\",\n",
        "    \"metrics.recall\",\n",
        "    \"metrics.f1\",\n",
        "    \"metrics.nb_hits\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "tCzFUId03lsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 10\n",
        "\n",
        "metrics_rdd = eval_df.rdd.map(lambda row: precision_recall_f1(\n",
        "    row[\"rec_movies\"][:K],  # coupe à K\n",
        "    row[\"test_movies\"]\n",
        "))\n",
        "\n",
        "precisions = metrics_rdd.map(lambda x: x[0]).collect()\n",
        "recalls    = metrics_rdd.map(lambda x: x[1]).collect()\n",
        "f1s        = metrics_rdd.map(lambda x: x[2]).collect()\n",
        "\n",
        "precision_at_k = sum(precisions) / len(precisions)\n",
        "recall_at_k    = sum(recalls) / len(recalls)\n",
        "f1_at_k        = sum(f1s) / len(f1s)\n",
        "\n",
        "print(f\"Precision@{K}: {precision_at_k}\")\n",
        "print(f\"Recall@{K}: {recall_at_k}\")\n",
        "print(f\"F1@{K}: {f1_at_k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcDj-0LohhBH",
        "outputId": "b295393a-6bae-4943-a13c-1f643fe5e508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 1.2991230919129589e-05\n",
            "Recall@10: 2.2196135526941244e-06\n",
            "F1@10: 2.602483360853983e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = eval_metrics.agg(\n",
        "    F.mean(\"precision\").alias(f'Precision@{K}'),\n",
        "    F.mean(\"recall\").alias(f'Recall@{K}'),\n",
        "    F.mean(\"f1\").alias(f'F1@{K}')\n",
        ")\n",
        "results.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs9j05cw3qU0",
        "outputId": "13f072f2-227d-44d1-c9e1-1e301bbf79a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|        Precision@10|           Recall@10|               F1@10|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|1.299123118716956...|2.219613567998886E-6|2.602483378217199E-6|\n",
            "+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste unique de tous les films recommandés\n",
        "all_recommended = final_recs.select(\"movieId\").distinct()\n",
        "# Nombre de films dans le catalogue à recommander (ex : tous les films testés, ou tous)\n",
        "total_catalog = df_sample.select(\"movieId\").distinct().count()\n",
        "\n",
        "coverage = all_recommended.count() / total_catalog\n",
        "print(f\"Coverage@{K} : {coverage:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnY4ikVJ3tCS",
        "outputId": "abdf6454-772a-4ad3-8ca5-29fc5237f1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage@10 : 0.0119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regroupement du top@k\n",
        "\n",
        "from pyspark.sql import functions as F, Window\n",
        "\n",
        "K = 10  # top@k à calculer\n",
        "\n",
        "# Si ce n'est pas déjà fait, on trie et on rajoute un rang pour les k premiers films recommandés par utilisateur\n",
        "w = Window.partitionBy(\"userId\").orderBy(F.desc(\"rating\"))\n",
        "topk_recs = final_recs.withColumn(\"rank\", F.row_number().over(w)).filter(F.col(\"rank\") <= K)\n",
        "\n",
        "# Regroupe les recommandations du top@k par utilisateur\n",
        "recs_k = topk_recs.groupBy(\"userId\").agg(F.collect_set(\"movieId\").alias(\"rec_movies\"))"
      ],
      "metadata": {
        "id": "ADeHH37neum3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure avec la vérité test\n",
        "\n",
        "eval_df = recs_k.join(test_positive, \"userId\", \"inner\")"
      ],
      "metadata": {
        "id": "3MdOAahhe3T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indice de Dice pour chaque utilisateur\n",
        "\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "def dice_index(rec_movies, test_movies):\n",
        "    set_rec = set(rec_movies or [])\n",
        "    set_test = set(test_movies or [])\n",
        "    inter = set_rec & set_test\n",
        "    denom = len(set_rec) + len(set_test)\n",
        "    return float(2 * len(inter) / denom) if denom > 0 else 0.0\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "dice_udf = udf(dice_index, FloatType())\n",
        "\n",
        "eval_df = eval_df.withColumn(\"dice\", dice_udf(\"rec_movies\", \"test_movies\"))"
      ],
      "metadata": {
        "id": "AbvllWBEfAcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Résultat\n",
        "eval_df.select(\"userId\", \"rec_movies\", \"test_movies\", \"dice\").show(10, truncate=False)\n",
        "\n",
        "# Pour la moyenne globale sur tous les utilisateurs, si souhaité :\n",
        "eval_df.agg(F.mean(\"dice\").alias(\"mean_dice\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIs4VTf4fJaU",
        "outputId": "a480da77-2f8f-4a22-9fd2-3cd353e06061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+\n",
            "|userId|rec_movies                              |test_movies                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |dice|\n",
            "+------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+\n",
            "|12    |[159896, 192949, 210621, 282453, 115987]|[1307, 5620, 1888, 2858]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |0.0 |\n",
            "|13    |[86288, 274047, 222368, 196167, 182527] |[912, 920, 597, 1088, 969, 733, 25, 1721, 11]                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |0.0 |\n",
            "|14    |[217747, 185291, 159761, 222605, 216663]|[8734, 33410, 4010, 2246, 2261]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |0.0 |\n",
            "|18    |[122015, 265364, 196167, 190707, 216663]|[2542, 46578, 32, 1172, 4881, 2028, 8961, 3983, 55276, 1704, 296, 1247, 69122, 56367, 1089, 59018, 1219, 59315, 37741]                                                                                                                                                                                                                                                                                                                                                                                                   |0.0 |\n",
            "|38    |[86288, 265364, 151989, 214720, 196167] |[1036, 53972, 91529, 1252]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0.0 |\n",
            "|46    |[86288, 265364, 151989, 196167, 216663] |[104636, 102125, 750, 112623, 4366, 73321, 102903, 62434, 63131, 99007, 48780, 111362, 90746, 88163, 97752, 81564, 116823, 106072, 100083, 7347]                                                                                                                                                                                                                                                                                                                                                                         |0.0 |\n",
            "|67    |[86288, 265364, 227612, 196167, 216663] |[1258, 5418, 33679, 1500, 1573, 2683, 8970, 33166, 5952, 587, 1183, 1219, 2302, 364]                                                                                                                                                                                                                                                                                                                                                                                                                                     |0.0 |\n",
            "|70    |[86288, 265364, 159761, 151989, 196167] |[2890, 33162, 2761, 8874, 8366, 8947, 47610, 33085, 5064, 7373, 8949, 5349, 5218, 6155, 30822, 7325, 30793, 8639, 37720, 858, 8937, 9018, 6934, 8866, 1208, 6957, 2857, 8983, 6218, 7438, 5943, 5283, 41566, 8529, 3578, 2947, 6874, 8798, 4973, 8981, 37727, 46578, 7153, 34048, 2841, 33794, 6595, 40815, 1136, 8969, 1573, 1777, 8665, 27808, 5065, 31685, 31431, 1059, 41573, 1619, 8640, 30825, 2346, 31427, 36401, 7160, 8961, 1688, 8636, 8984, 1711, 1080, 4020, 4274, 4499, 8709, 6952, 7156, 33166, 8957, 4899]|0.0 |\n",
            "|93    |[265364, 196167, 190707, 164937, 216663]|[1199, 1018, 750, 3044, 924, 32, 904, 671, 4039, 1913, 1086, 695, 1805, 1320, 1212, 3471, 2571, 1097]                                                                                                                                                                                                                                                                                                                                                                                                                    |0.0 |\n",
            "|107   |[86288, 185291, 159761, 154280, 196167] |[1097, 63992, 1258, 39231, 3793, 49272, 2762, 7321, 2683, 165, 3431, 68205, 26560, 56156, 6365, 64969, 1196, 260, 56367, 85056, 79132, 63082, 6874, 6686, 54503, 74851, 110]                                                                                                                                                                                                                                                                                                                                             |0.0 |\n",
            "+------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------------------+\n",
            "|           mean_dice|\n",
            "+--------------------+\n",
            "|2.602483378217199E-6|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_ZK5DjJ7mceU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Recommandation de films basée sur le contenu (genres, TF-IDF, similarité cosinus)"
      ],
      "metadata": {
        "id": "oaoS492CwtzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction et vectorisation des genres (prétraitement)\n",
        "\n",
        "from pyspark.sql.functions import split, col\n",
        "train = train.withColumn(\"genres_list\", split(col(\"genres\"), \"\\|\"))\n",
        "test  = test.withColumn(\"genres_list\", split(col(\"genres\"), \"\\|\"))"
      ],
      "metadata": {
        "id": "mzZCy5PO7VcI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorisation TF-IDF: application du même modèle TF-IDF sur tout le catalogue de films à recommander et sur le train\n",
        "\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "cv = CountVectorizer(inputCol=\"genres_list\", outputCol=\"raw_features\", minDF=2)  # minDF réduit le bruit\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "pipeline = Pipeline(stages=[cv, idf])\n",
        "\n",
        "tfidf_model = pipeline.fit(train)\n",
        "train_tfidf = tfidf_model.transform(train)\n",
        "test_tfidf = tfidf_model.transform(test)"
      ],
      "metadata": {
        "id": "7iSthXLk7bho"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Construction des Profils Utilisateur\n",
        "\n",
        "    #Filtrage des films appréciés dans le train :\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "seuil_like = 4.0\n",
        "liked_train = train_tfidf.filter(col(\"rating\") >= seuil_like)"
      ],
      "metadata": {
        "id": "YYFTroKy7i7W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrégation (profil moyen) :\n",
        "# Spark n’offre pas de moyenne native sur un vector. On les convertit en Array pour faire une moyenne proprement.\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import collect_list, udf\n",
        "import numpy as np\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "\n",
        "def mean_vectors(arrs):\n",
        "    if not arrs: return []\n",
        "    arrs = [np.array(a.toArray()) if hasattr(a, 'toArray') else np.array(a) for a in arrs]\n",
        "    return (np.mean(arrs, axis=0)).tolist()\n",
        "\n",
        "mean_vectors_udf = udf(mean_vectors, ArrayType(DoubleType()))\n",
        "\n",
        "user_profiles = liked_train.groupBy(\"userId\").agg(\n",
        "    collect_list(\"features\").alias(\"arrs\")\n",
        ").withColumn(\"user_profile\", mean_vectors_udf(\"arrs\"))"
      ],
      "metadata": {
        "id": "qtSa_0Xz7n3L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Catalogue de recommandation (films candidats), en utilisant tous les films du catalogue, pas seulement le train\n",
        "\n",
        "movies = spark.read.csv(\"/content/drive/MyDrive/ml-32m/movies.csv\", header=True, inferSchema=True)\n",
        "df_catalog = movies.select(\"movieId\", \"genres\").distinct()\n",
        "df_catalog = df_catalog.withColumn(\"genres_list\", split(col(\"genres\"), \"\\|\"))\n",
        "catalog_tfidf = tfidf_model.transform(df_catalog).select(\"movieId\", \"features\")"
      ],
      "metadata": {
        "id": "bF6PavpO72vG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul de la similarité cosinus\n",
        "\n",
        "    # Implémentation UDF\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import numpy as np\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    arr1, arr2 = np.array(v1), np.array(v2)\n",
        "    num = np.dot(arr1, arr2)\n",
        "    denom = np.linalg.norm(arr1) * np.linalg.norm(arr2)\n",
        "    return float(num / denom) if denom else 0.0\n",
        "\n",
        "cosine_udf = udf(cosine_sim, DoubleType())"
      ],
      "metadata": {
        "id": "1A3s2S5C77Kr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Croisement profils utilisateurs et catalogue :\n",
        "\n",
        "\n",
        "user_films = user_profiles.crossJoin(catalog_tfidf)\n",
        "user_films = user_films.withColumn(\n",
        "    \"cosine_sim\",\n",
        "    cosine_udf(\"user_profile\", \"features\")\n",
        ")"
      ],
      "metadata": {
        "id": "YTQb5xO98BR4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtrage des films déjà vus\n",
        "\n",
        "    # Ejection des films déjà notés par chaque utilisateur :\n",
        "\n",
        "df_seen = train.select(\"userId\", \"movieId\").distinct()\n",
        "user_films = user_films.join(df_seen, on=[\"userId\", \"movieId\"], how=\"left_anti\")"
      ],
      "metadata": {
        "id": "vnUuuMpd8GG6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-N recommandations par similarité\n",
        "\n",
        "    # Classement et coupe pour Top-N (exemple : N=10) :\n",
        "\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "N = 10\n",
        "w = Window.partitionBy(\"userId\").orderBy(col(\"cosine_sim\").desc())\n",
        "topn_recs = user_films.withColumn(\"rank\", row_number().over(w)) \\\n",
        "    .filter(col(\"rank\") <= N) \\\n",
        "    .select(\"userId\", \"movieId\", \"cosine_sim\", \"rank\")"
      ],
      "metadata": {
        "id": "2MaFwyLV8MCl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérité de test (films appréciés dans le test)\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "test_positive = test.filter(col(\"rating\") >= seuil_like).groupBy(\"userId\") \\\n",
        "    .agg(F.collect_set(\"movieId\").alias(\"test_movies\"))"
      ],
      "metadata": {
        "id": "-PrsAJ-y8VHH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jointure recommandations et vérité\n",
        "\n",
        "eval_df = topn_recs.join(test_positive, \"userId\", \"left\") \\\n",
        "    .withColumn(\"hit\", F.expr(\"array_contains(test_movies, movieId)\").cast(\"int\"))"
      ],
      "metadata": {
        "id": "0YK1loID8avF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommandations de k films similaires à un film donné\n",
        "'''Pour un film cible, il suffit de :\n",
        "\n",
        "    Extraire le vecteur TF-IDF (basé sur les genres) correspondant à ce film dans le catalogue.\n",
        "\n",
        "    Calculer la similarité cosinus entre ce vecteur et celui de tous les autres films du catalogue (hors lui-même).\n",
        "\n",
        "    Trier les scores de similarité décroissants.\n",
        "\n",
        "    Afficher les k premiers résultats.'''\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import DoubleType\n",
        "import numpy as np\n",
        "\n",
        "movie_id_cible = 30707  # ID du film pour lequel on veut des recommandations\n",
        "k = 5\n",
        "\n",
        "# Récupération du profil TF-IDF du film cible\n",
        "film_query_vec = catalog_tfidf.filter(col(\"movieId\") == movie_id_cible).select(\"features\").collect()[0][0]\n",
        "\n",
        "# Definition de lan fonction cosine_sim UDF qui capture le film_query_vec\n",
        "def cosine_sim_udf_factory(query_vec):\n",
        "    def cosine_sim(v1):\n",
        "        arr1, arr2 = np.array(v1.toArray()), np.array(query_vec.toArray())\n",
        "        num = np.dot(arr1, arr2)\n",
        "        denom = np.linalg.norm(arr1) * np.linalg.norm(arr2)\n",
        "        return float(num / denom) if denom else 0.0\n",
        "    return udf(cosine_sim, DoubleType())\n",
        "\n",
        "# Création de l'instance UDF avec le vecteur de requête spécifique\n",
        "cosine_udf_instance = cosine_sim_udf_factory(film_query_vec)\n",
        "\n",
        "# Calcul de la similarité cosinus en utilisant l'instance UDF\n",
        "recs_film = catalog_tfidf.withColumn(\n",
        "    \"cosine_sim\",\n",
        "    cosine_udf_instance(col(\"features\")) # Ne passer que la colonne desfeatures\n",
        ")\n",
        "\n",
        "\n",
        "# Suppression du film d'origine et sélection des k plus proches\n",
        "recs_film = recs_film.filter(col(\"movieId\") != movie_id_cible) \\\n",
        "    .orderBy(col(\"cosine_sim\").desc()) \\\n",
        "    .limit(k)\n",
        "\n",
        "recs_film.select(\"movieId\", \"cosine_sim\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbqSDK5T8iLX",
        "outputId": "2bc3021d-394d-43e1-c3b2-bd1c8dc02db1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|movieId|cosine_sim|\n",
            "+-------+----------+\n",
            "|    396|       1.0|\n",
            "|    636|       1.0|\n",
            "|    452|       1.0|\n",
            "|    388|       1.0|\n",
            "|    491|       1.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des films proches de movieId = 30707 (Million Dollar Baby)\n",
        "\n",
        "movies_unique = movies.select(\"movieId\", \"title\", \"genres\").dropDuplicates([\"movieId\"])\n",
        "\n",
        "recs_film_with_infos = recs_film.join(movies_unique, on=\"movieId\", how=\"left\")\n",
        "\n",
        "recs_film_with_infos.select(\"movieId\", \"title\", \"genres\", \"cosine_sim\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBHEzhSNIftT",
        "outputId": "65440f13-26aa-4df0-8ba7-fffc671ffdce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------+------+----------+\n",
            "|movieId|title                         |genres|cosine_sim|\n",
            "+-------+------------------------------+------+----------+\n",
            "|396    |Fall Time (1995)              |Drama |1.0       |\n",
            "|636    |Frisk (1995)                  |Drama |1.0       |\n",
            "|452    |Widows' Peak (1994)           |Drama |1.0       |\n",
            "|388    |Boys Life (1995)              |Drama |1.0       |\n",
            "|491    |Man Without a Face, The (1993)|Drama |1.0       |\n",
            "+-------+------------------------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "\n",
        "recs_film_with_infos = recs_film_with_infos.withColumn(\"genres_list\", split(col(\"genres\"), \"\\|\"))"
      ],
      "metadata": {
        "id": "pw_LFxNH9xG6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs_film_with_infos.select(\"movieId\", \"title\", \"genres_list\", \"cosine_sim\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVjd9FO4I5vO",
        "outputId": "5d36e30e-d3ef-4f1a-de62-0d401258a5db"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------+-----------+----------+\n",
            "|movieId|title                         |genres_list|cosine_sim|\n",
            "+-------+------------------------------+-----------+----------+\n",
            "|396    |Fall Time (1995)              |[Drama]    |1.0       |\n",
            "|636    |Frisk (1995)                  |[Drama]    |1.0       |\n",
            "|452    |Widows' Peak (1994)           |[Drama]    |1.0       |\n",
            "|388    |Boys Life (1995)              |[Drama]    |1.0       |\n",
            "|491    |Man Without a Face, The (1993)|[Drama]    |1.0       |\n",
            "+-------+------------------------------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "QKK9FE_aJssw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = spark.read.csv(\"/content/drive/MyDrive/ml-32m/ratings.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "-8IChMglJuf-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "# On trie et sépare les notes utilisateur aléatoirement\n",
        "ratings = ratings.orderBy(rand())\n",
        "training = ratings.sampleBy(\"userId\", fractions={u: 0.8 for u in ratings.select(\"userId\").distinct().rdd.flatMap(lambda x: x).collect()}, seed=42)\n",
        "test = ratings.subtract(training)"
      ],
      "metadata": {
        "id": "abxx6LmXJ2y9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction de recommandation par utilisateur\n",
        "\n",
        "\n",
        "def get_top_k_recommendations(user_id, k):\n",
        "    # 1. Récupère les films notés par l'utilisateur dans le train set\n",
        "    user_history = training.filter(col(\"userId\") == user_id).select(\"movieId\").collect()\n",
        "    watched_ids = [row[\"movieId\"] for row in user_history]\n",
        "\n",
        "    # 2. Récupère les vecteurs TF-IDF des films vus\n",
        "    user_profile = catalog_tfidf.filter(col(\"movieId\").isin(watched_ids))\n",
        "\n",
        "    # 3. Calcule une moyenne du profil utilisateur\n",
        "    from pyspark.ml.linalg import Vectors, DenseVector\n",
        "    import numpy as np\n",
        "\n",
        "    vectors = np.array([vec[\"features\"].toArray() for vec in user_profile.collect()])\n",
        "    if len(vectors) == 0:\n",
        "        return []\n",
        "    avg_profile = Vectors.dense(np.mean(vectors, axis=0))\n",
        "\n",
        "    # 4. Calcule la similarité avec tout le catalogue\n",
        "    cosine_udf = cosine_sim_udf_factory(avg_profile)\n",
        "    scores = catalog_tfidf.withColumn(\"cosine_sim\", cosine_udf(col(\"features\")))\n",
        "\n",
        "    # 5. Retire les films déjà vus\n",
        "    scores = scores.filter(~col(\"movieId\").isin(watched_ids))\n",
        "\n",
        "    # 6. Retourne les k premiers movieId\n",
        "    top_k = scores.orderBy(col(\"cosine_sim\").desc()).limit(k).select(\"movieId\").collect()\n",
        "    return [row[\"movieId\"] for row in top_k]\n"
      ],
      "metadata": {
        "id": "tZ-NsQIXJ7gt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision@k et Recall@k"
      ],
      "metadata": {
        "id": "ouyAMHA2KoaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coverage"
      ],
      "metadata": {
        "id": "ZHbvY35nKw3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indice de Dice"
      ],
      "metadata": {
        "id": "ofvc5NNKK4Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthèse des métriques\n",
        "\n",
        "print(f\"Precision@{k} = {precision_at_k:.4f}\")\n",
        "print(f\"Recall@{k} = {recall_at_k:.4f}\")\n",
        "print(f\"Coverage = {coverage:.4f}\")\n",
        "print(f\"Dice coefficient = {dice_coeff:.4f}\")"
      ],
      "metadata": {
        "id": "_NeZ2fHCLBPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Recommandation Basée sur les Proximités Utilisateurs (User-KNN)"
      ],
      "metadata": {
        "id": "Sw-3b6Dc9V5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Préparation des données\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set a higher value for spark.sql.pivotMaxValues\n",
        "spark.conf.set(\"spark.sql.pivotMaxValues\", 100000) # Set to a value higher than the number of unique movies\n",
        "\n",
        "# Extraire du DataFrame PySpark (pour manipuler numpy)\n",
        "pivot_df = train.groupBy(\"userId\").pivot(\"movieId\").agg(F.first(\"rating\"))\n",
        "pivot_pd = pivot_df.toPandas().set_index(\"userId\").fillna(0)\n",
        "user_item_matrix = pivot_pd.values  # Matrice numpy users x items\n",
        "user_ids = pivot_pd.index.values"
      ],
      "metadata": {
        "id": "0JZxcPf29Zfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesure de similarité entre utilisateurs (similarité cosinus)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(user_item_matrix)\n",
        "# Diagonale = 1 (identité utilisateur)"
      ],
      "metadata": {
        "id": "Bbvam3w598aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recherche des k voisins les plus proches\n",
        "\n",
        "k = 10  # nombre de voisins à considérer\n",
        "top_k_indices = np.argsort(-similarity_matrix, axis=1)[:, 1:k+1]  # évite l'utilisateur lui-même (colonne 0)"
      ],
      "metadata": {
        "id": "eT8tgczz-JWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Génération des recommandations\n",
        "\n",
        "Pour un utilisateur donné :\n",
        "\n",
        "    On aboutit à :\n",
        "\n",
        "        Ses k voisins les plus similaires.\n",
        "\n",
        "        Les notes qu'ils ont donné à chaque film.\n",
        "\n",
        "        On moyenne/pondère les notes pour chaque film non vu par l'utilisateur cible.\n",
        "\n",
        "        On trie les scores et propose les meilleurs films.\n",
        "'''\n",
        "\n",
        "def recommend_for_user(user_idx, user_item_matrix, top_k_indices, user_ids, N=10):\n",
        "    neighbors = top_k_indices[user_idx]\n",
        "    # Moyenne (ou pondérée par similarité) des notes des voisins, sur les films non vus\n",
        "    neighbor_ratings = user_item_matrix[neighbors]\n",
        "    user_ratings = user_item_matrix[user_idx]\n",
        "    already_seen = set(np.where(user_ratings > 0)[0])\n",
        "\n",
        "    # Calcul du score moyen\n",
        "    mean_scores = neighbor_ratings.mean(axis=0)\n",
        "    scores = [(i, score) for i, score in enumerate(mean_scores) if i not in already_seen]\n",
        "    # Top-N recommandations (par score décroissant)\n",
        "    top_n = sorted(scores, key=lambda x: -x[1])[:N]\n",
        "    return top_n  # indices des films à recommander\n",
        "\n",
        "# Pour tous les utilisateurs\n",
        "recs_by_user = {user_ids[i]: recommend_for_user(i, user_item_matrix, top_k_indices, user_ids) for i in range(len(user_ids))}"
      ],
      "metadata": {
        "id": "lN8v7oWB-ToW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommandation Hybride : KNN Utilisateur + Genres"
      ],
      "metadata": {
        "id": "la_X30nc_V6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Préparer les données utilisateur-film et d'intégration des genres\n",
        "\n",
        "from pyspark.sql.functions import split, col, collect_set\n",
        "\n",
        "# train : userId, movieId, rating, genres (séparés par |)\n",
        "train = train.withColumn(\"genres_list\", split(col(\"genres\"), \"\\\\|\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "btOgEzg-_bAO",
        "outputId": "e4cf40a9-d295-45b3-800a-a36aab489c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1210308290.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train : userId, movieId, rating, genres (séparés par |)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genres_list\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genres\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\\|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Établir le profil « genre préféré » de chaque utilisateur\n",
        "\n",
        "user_genres = train.filter(col(\"rating\") >= 4) \\\n",
        "    .select(\"userId\", \"genres_list\") \\\n",
        "    .withColumn(\"genre\", F.explode(\"genres_list\")) \\\n",
        "    .groupBy(\"userId\") \\\n",
        "    .agg(collect_set(\"genre\").alias(\"preferred_genres\"))"
      ],
      "metadata": {
        "id": "ujkKSRuG_gJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construire la matrice user-item via pivot (ratings explicites uniquement)\n",
        "\n",
        "user_item_df = train.groupBy(\"userId\").pivot(\"movieId\").agg(F.first(\"rating\"))\n",
        "user_item_pd = user_item_df.toPandas().set_index(\"userId\").fillna(0)\n",
        "user_ids = user_item_pd.index.values"
      ],
      "metadata": {
        "id": "H7_T0mis_lZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer la similarité entre utilisateurs (KNN collaboratif seulement)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "user_item_matrix = user_item_pd.values\n",
        "sim_matrix = cosine_similarity(user_item_matrix)\n",
        "# On force la diagonale à 0 (évite d'être son propre voisin)\n",
        "np.fill_diagonal(sim_matrix, 0)\n",
        "k = 10  # voisins\n",
        "\n",
        "# Indices des k plus proches voisins pour chaque utilisateur\n",
        "topk_neighbor_indices = np.argsort(-sim_matrix, axis=1)[:, :k]"
      ],
      "metadata": {
        "id": "mW40QgyL_oKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gérer le cold start et la diversité dans la recommandation\n",
        "\n",
        "# - Si un utilisateur n'a PAS de voisins (cold start), CF: => recommandation popularité et/ou par genre préféré\n",
        "# - Pour la diversité, on filtre ou pondère la liste finale selon qu'un film apporte un genre « différent » des habitudes\n",
        "\n",
        "def get_user_genres(user_id):\n",
        "    # mapping userId -> genres préférés (set)\n",
        "    row = user_genres.filter(col(\"userId\") == user_id).collect()\n",
        "    return set(row[0][\"preferred_genres\"]) if row else set()\n",
        "\n",
        "movies_genres = train.select(\"movieId\", \"genres_list\").distinct()\n",
        "movies_genres_dict = dict(movies_genres.collect())"
      ],
      "metadata": {
        "id": "XbD2DExV_viL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Générer les recommandations hybrides pour un utilisateur\n",
        "\n",
        "\n",
        "def recommend_knn_genres(user_idx, N=10):\n",
        "    neighbors = topk_neighbor_indices[user_idx]\n",
        "    user_seen = set(np.where(user_item_matrix[user_idx] > 0)[0])\n",
        "    scores = np.zeros(user_item_matrix.shape[1])\n",
        "\n",
        "    for n_idx in neighbors:\n",
        "        neighbor_ratings = user_item_matrix[n_idx]\n",
        "        scores += neighbor_ratings\n",
        "\n",
        "    # On ne recommande pas les films déjà vus\n",
        "    for idx in user_seen:\n",
        "        scores[idx] = -np.inf\n",
        "\n",
        "    # On priorise : genre jamais vu pour l'utilisateur (diversité)\n",
        "    user_id = user_ids[user_idx]\n",
        "    user_fav_genres = get_user_genres(user_id)\n",
        "\n",
        "    movie_indices = np.argsort(-scores)\n",
        "    recs = []\n",
        "    for i in movie_indices:\n",
        "        if len(recs) >= N:\n",
        "            break\n",
        "        movie_id = user_item_pd.columns[i]\n",
        "        film_genres = set(movies_genres_dict.get(movie_id, []))\n",
        "        # Option diversity : push si au moins un genre nouveau pour user\n",
        "        if len(film_genres - user_fav_genres) > 0 or not user_fav_genres:\n",
        "            recs.append((movie_id, scores[i]))\n",
        "    # Cold start si pas de recs : on propose les k films populaires alignés avec genres préférés\n",
        "    if len(recs) == 0:\n",
        "        for i in movie_indices:\n",
        "            movie_id = user_item_pd.columns[i]\n",
        "            film_genres = set(movies_genres_dict.get(movie_id, []))\n",
        "            if len(film_genres & user_fav_genres) > 0:\n",
        "                recs.append((movie_id, scores[i]))\n",
        "                if len(recs) >= N:\n",
        "                    break\n",
        "    return recs[:N]"
      ],
      "metadata": {
        "id": "46412JHL_2cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliquer à tous les utilisateurs\n",
        "\n",
        "recommendations = {user_ids[i]: recommend_knn_genres(i, N=10) for i in range(len(user_ids))}"
      ],
      "metadata": {
        "id": "kcEBQcUxABuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwaM7EMZA1aF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}